{"cells":[{"metadata":{"_uuid":"f8e1b264571df7a1e04637f36289bb64682aaa16"},"cell_type":"markdown","source":"**Importing required modules**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras import layers,models,optimizers\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom pathlib import Path","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"f8580ba6a6acaf61e7615a3c0f1c079a7e1381b0"},"cell_type":"markdown","source":"**Initializing parameters**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir = Path('../input/training/training')\ntest_dir = Path('../input/validation/validation')\n# height and width should be 224 as we are going to use vgg16 and its input shape is 224*224*3\nheight=224\nwidth=224\nchannels=3\nbatch_size=32\nseed=99","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"f9cb602e1a530324da1ac8db250e36397e10a02e"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"17d7a8bda91e21e9ef74ffb808cdcd2cdb152d64"},"cell_type":"markdown","source":"**Using data generators for applying random distortions to input data**"},{"metadata":{"trusted":true,"_uuid":"a2b677ee21c94684ec8dd359edc24a0bc583454b","collapsed":true},"cell_type":"code","source":"train_batches=ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True).flow_from_directory(train_dir,\n                                                         target_size = (height, width),\n                                                         batch_size = batch_size,\n                                                         seed = 2,\n                                                         class_mode = \"categorical\")\nvalidation_batches=ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True).flow_from_directory(test_dir,\n                                                              target_size = (height, width),\n                                                              batch_size = batch_size,\n                                                              seed = 2,\n                                                              class_mode = \"categorical\")","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"38879de956b13cf6e92a772437e351a7994b6934"},"cell_type":"markdown","source":"**Use vgg16 model pretrained on imagenet (*this may not work in kaggle kernel, showing some url fetch error but should work on other platforms*)**"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"b618874b374c14c6d4c02f5eba1c69a80b78399f","collapsed":true},"cell_type":"code","source":"vgg = applications.VGG16(weights = \"imagenet\")","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"321f6ff507416802bc1b338233618a5754dad8c8"},"cell_type":"markdown","source":"**Initialize a sequential model and add all the layers that are corresponding to vgg16**"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"4b7c1f361631858940ad4c42a0ffe206d59aa268","collapsed":true},"cell_type":"code","source":"model = models.Sequential()\nfor layer in vgg.layers:\n    model.add(layer)\nmodel.layers.pop()\n#removing the last layer as it is classifying  1000 classes","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"9ff66fce8d1ca8096a7f1efebe17ee570f820743"},"cell_type":"markdown","source":"**Since we need to train only the last layer , make all the weights non trainable(freeze them)**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c931538166248c2b8ef5c0b4112616164a749f14"},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False\n#last layer for classifying 10 classes of monkeys\nmodel.add(layers.Dense(10, activation = \"softmax\"))","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"517a63c0cc52a7377df97fadf1de20eb20223152"},"cell_type":"markdown","source":"**Compiling and training our model with the prepared data generators**"},{"metadata":{"trusted":true,"_uuid":"ada05f3ba80b999ad2b8e8357c5de740f455260c","collapsed":true},"cell_type":"code","source":"model.compile(optimizers.Adam(lr = 0.009), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\nmodel.fit_generator(train_batches,\n                    steps_per_epoch = 1097//batch_size,\n                    validation_data = validation_batches,\n                    validation_steps = 4,\n                    epochs = 5,\n                    verbose  = 2)\n#you can fine tune the epochs and other hyperparams to get proper accuracy.","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5153350e5b6e1235e0dd019a5043b6c2b2f8552a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}